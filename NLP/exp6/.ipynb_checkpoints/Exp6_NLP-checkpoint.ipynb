{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7IV5__tAvTH"
   },
   "source": [
    "Aim : To implement Entity Identification for Pronoun Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcxhuzqyTy3I",
    "outputId": "dbbf34c9-4dcf-4a8c-8bf6-a0de5ba00f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
      "\r",
      "\u001b[K     |█▏                              | 10kB 13.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 20kB 20.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 30kB 21.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 40kB 14.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 51kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 61kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 71kB 6.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 81kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 92kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 102kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 112kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 122kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 133kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 143kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 153kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 163kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 174kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 184kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 194kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 204kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 215kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 225kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 235kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 245kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 256kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 266kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 276kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 286kB 7.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (56.0.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
      "Installing collected packages: stanza\n",
      "Successfully installed stanza-1.2\n"
     ]
    }
   ],
   "source": [
    "# Install stanza; note that the prefix \"!\" is not needed if you are running in a terminal\n",
    "!pip install stanza\n",
    "\n",
    "# Import stanza\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIC_M-B4T7vd",
    "outputId": "4445612e-08d8-41c8-c0e4-aece41ab5e6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-06 04:56:26 INFO: Installing CoreNLP package into ./corenlp...\n",
      "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 504M/504M [02:38<00:00, 3.19MB/s]\n",
      "2021-05-06 04:59:07 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
     ]
    }
   ],
   "source": [
    "# Download the Stanford CoreNLP package with Stanza's installation command\n",
    "# This'll take several minutes, depending on the network speed\n",
    "corenlp_dir = './corenlp'\n",
    "stanza.install_corenlp(dir=corenlp_dir)\n",
    "\n",
    "# Set the CORENLP_HOME environment variable to point to the installation location\n",
    "import os\n",
    "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zmgfq-O-UAqf"
   },
   "outputs": [],
   "source": [
    "# Import client module\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwCqsWYYUKEf",
    "outputId": "f56e35a9-9d01-4d3c-f1f5-b38dbb2bd2b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-06 05:04:02 INFO: Writing properties to tmp file: corenlp_server-d9ad1c6d9c5a458a.props\n",
      "2021-05-06 05:04:02 INFO: Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-d9ad1c6d9c5a458a.props -annotators tokenize,ssplit,pos,lemma,ner -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stanza.server.client.CoreNLPClient object at 0x7f6bbc6d7950>\n"
     ]
    }
   ],
   "source": [
    "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
    "client = CoreNLPClient(\n",
    "    annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], \n",
    "    memory='4G', \n",
    "    endpoint='http://localhost:9001',\n",
    "    be_quiet=True)\n",
    "print(client)\n",
    "\n",
    "# Start the background server and wait for some time\n",
    "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
    "client.start()\n",
    "import time; time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CrYHNNx5UV7b"
   },
   "outputs": [],
   "source": [
    "# Annotate some text\n",
    "text = \"Albert Einstein was a German-born theoretical physicist. He developed the theory of relativity. He is a great man.\"\n",
    "document = client.annotate(text)\n",
    "#print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osA3Gyk7VzFb",
    "outputId": "bbd6a044-f2b6-4bf6-c101-e9d178a5fac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word        \tLemma       \tPOS   \tNER\n",
      "[Sentence 1]\n",
      "Albert      \tAlbert      \tNNP   \tPERSON\n",
      "Einstein    \tEinstein    \tNNP   \tPERSON\n",
      "was         \tbe          \tVBD   \tO\n",
      "a           \ta           \tDT    \tO\n",
      "German      \tgerman      \tJJ    \tNATIONALITY\n",
      "-           \t-           \tHYPH  \tO\n",
      "born        \tbear        \tVBN   \tO\n",
      "theoretical \ttheoretical \tJJ    \tTITLE\n",
      "physicist   \tphysicist   \tNN    \tTITLE\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 2]\n",
      "He          \the          \tPRP   \tO\n",
      "developed   \tdevelop     \tVBD   \tO\n",
      "the         \tthe         \tDT    \tO\n",
      "theory      \ttheory      \tNN    \tO\n",
      "of          \tof          \tIN    \tO\n",
      "relativity  \trelativity  \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 3]\n",
      "He          \the          \tPRP   \tO\n",
      "is          \tbe          \tVBZ   \tO\n",
      "a           \ta           \tDT    \tO\n",
      "great       \tgreat       \tJJ    \tO\n",
      "man         \tman         \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all tokens in all sentences, and print out the word, lemma, pos and ner tags\n",
    "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\n",
    "\n",
    "for i, sent in enumerate(document.sentence):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for t in sent.token:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkeO7sBxV_ii",
    "outputId": "39418b03-a6e5-4855-effb-57cbf257eed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention                       \tType\n",
      "Albert Einstein               \tPERSON\n",
      "German                        \tNATIONALITY\n",
      "theoretical physicist         \tTITLE\n",
      "He                            \tPERSON\n",
      "He                            \tPERSON\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all detected entity mentions\n",
    "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
    "\n",
    "for sent in document.sentence:\n",
    "    for m in sent.mentions:\n",
    "       print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mXhiqEpDYyp"
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3Zhs70FDcuh",
    "outputId": "ac32facb-e430-4048-c01a-4c6760e45ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word        \tLemma       \tPOS   \tNER\n",
      "[Sentence 1]\n",
      "Rafael      \tRafael      \tNNP   \tPERSON\n",
      "Nadal       \tNadal       \tNNP   \tPERSON\n",
      "is          \tbe          \tVBZ   \tO\n",
      "a           \ta           \tDT    \tO\n",
      "Spanish     \tspanish     \tJJ    \tNATIONALITY\n",
      "professional\tprofessional\tJJ    \tO\n",
      "tennis      \ttennis      \tNN    \tTITLE\n",
      "player      \tplayer      \tNN    \tTITLE\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 2]\n",
      "He          \the          \tPRP   \tO\n",
      "is          \tbe          \tVBZ   \tO\n",
      "called      \tcall        \tVBN   \tO\n",
      "the         \tthe         \tDT    \tO\n",
      "king        \tking        \tNN    \tTITLE\n",
      "of          \tof          \tIN    \tO\n",
      "the         \tthe         \tDT    \tO\n",
      "clay        \tclay        \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 3]\n",
      "He          \the          \tPRP   \tO\n",
      "is          \tbe          \tVBZ   \tO\n",
      "ranked      \trank        \tVBN   \tO\n",
      "world       \tworld       \tNN    \tO\n",
      "no.         \tno.         \tNN    \tO\n",
      "2           \t2           \tCD    \tNUMBER\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "Mention                       \tType\n",
      "Rafael Nadal                  \tPERSON\n",
      "Spanish                       \tNATIONALITY\n",
      "tennis player                 \tTITLE\n",
      "king                          \tTITLE\n",
      "He                            \tPERSON\n",
      "2                             \tNUMBER\n",
      "He                            \tPERSON\n"
     ]
    }
   ],
   "source": [
    "# Annotate some text\n",
    "text = \"Rafael Nadal is a Spanish professional tennis player. He is called the king of the clay. He is ranked world no. 2.\"\n",
    "document = client.annotate(text)\n",
    "# Iterate over all tokens in all sentences, and print out the word, lemma, pos and ner tags\n",
    "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\n",
    "\n",
    "for i, sent in enumerate(document.sentence):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for t in sent.token:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\n",
    "    print(\"\")\n",
    "# Iterate over all detected entity mentions\n",
    "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
    "\n",
    "for sent in document.sentence:\n",
    "    for m in sent.mentions:\n",
    "       print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I1bUr1hWzr_",
    "outputId": "09d7d093-5f6d-4ebe-aefa-7517f3b8602c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    236 /bin/bash -c ps -o pid,cmd | grep java\n",
      "    238 grep java\n"
     ]
    }
   ],
   "source": [
    "# Shut down the background CoreNLP server\n",
    "client.stop()\n",
    "\n",
    "time.sleep(10)\n",
    "!ps -o pid,cmd | grep java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0K1bX5rPEsCR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "64_BECMPNA_Exp6_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
